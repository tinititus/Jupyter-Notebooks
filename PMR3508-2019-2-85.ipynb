{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMR3508 - Trabalho 2: Aplicação de diferentes classificadores na base Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Id\", \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../input/test_data.csv\", names = column_names, na_values='?').drop(0, axis = 0).reset_index(drop = True)\n",
    "train_data = pd.read_csv(\"../input/train_data.csv\", names = column_names, na_values='?').drop(0, axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploração e tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Podemos descartar as colunas 'Id' (sem utilidade para classificação) e 'Education' (informação já quantificada pela coluna Education-Num):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(\"Id\", axis = 1)\n",
    "train_data = train_data.drop(\"Education\", axis = 1)\n",
    "test_data = test_data.drop(\"Id\", axis = 1)\n",
    "test_data = test_data.drop(\"Education\", axis = 1)\n",
    "test_data = test_data.drop(\"Income\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'] = train_data['Age'].astype('int64')\n",
    "train_data['fnlwgt'] = train_data['fnlwgt'].astype('int64')\n",
    "train_data['Education-Num'] = train_data['Education-Num'].astype('int64')\n",
    "train_data['Capital Gain'] = train_data['Capital Gain'].astype('int64')\n",
    "train_data['Capital Loss'] = train_data['Capital Loss'].astype('int64')\n",
    "train_data['Hours per week'] = train_data['Hours per week'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna('missing')  # Preencher dados faltantes com a string 'missing'\n",
    "test_data = test_data.fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_null_values(data):  # Returns a DataFrame with count of null values\n",
    "    \n",
    "    \n",
    "    counts_null = []\n",
    "    for column in data.columns:\n",
    "        counts_null.append(data[column].isnull().sum())\n",
    "    counts_null = np.asarray(counts_null)\n",
    "\n",
    "    counts_null = pd.DataFrame({'feature': data.columns, 'count.': counts_null,\n",
    "                                'freq. [%]': 100*counts_null/data.shape[0]}).set_index('feature', drop = True)\n",
    "    counts_null = counts_null.sort_values(by = 'count.', ascending = False)\n",
    "    \n",
    "    return counts_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_null_values(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora não há mais dados faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_analysis = train_data.apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = train_data_analysis.corr()\n",
    "sns.set()\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(corr_mat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_analysis.corr().Income.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(train_data_analysis.corr().Income).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleção dos atributos de maior correlação com a variável de interesse, os quais serão utilizados pelos classificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[[\"Capital Gain\", \"Education-Num\", \"Relationship\", \"Age\", \"Hours per week\", \"Sex\", \"Marital Status\", \n",
    "                      \"Capital Loss\"]].apply(preprocessing.LabelEncoder().fit_transform)\n",
    "y_train = train_data.Income\n",
    "\n",
    "x_test = test_data[[\"Capital Gain\", \"Education-Num\", \"Relationship\", \"Age\", \"Hours per week\", \"Sex\", \"Marital Status\", \n",
    "                      \"Capital Loss\"]].apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()  # Scaler para normalizar os dados contidos nos atributos\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 23, p = 1)\n",
    "start = time.time()\n",
    "scores = cross_val_score(knn, x_train, y_train, cv = 10)\n",
    "print('K-Nearest Neighbors CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(scores.mean(), scores.std()))\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "knn.fit(x_train, y_train)\n",
    "y_predict_knn = knn.predict(x_test)\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(solver = 'lbfgs', C = 1.0, penalty = 'l2', warm_start =  True)\n",
    "start = time.time()\n",
    "log_scores = cross_val_score(log_clf, x_train, y_train, cv = 10)\n",
    "print('Logistic Regression CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(log_scores.mean(), log_scores.std()))\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "log_clf.fit(x_train, y_train)\n",
    "y_predict_log = log_clf.predict(x_test)\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 700, max_depth = 12)\n",
    "start = time.time()\n",
    "rf_scores = cross_val_score(rf_clf, x_train, y_train, cv = 10)\n",
    "print('Random Forest CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(rf_scores.mean(), rf_scores.std()))\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf_clf.fit(x_train, y_train)\n",
    "y_predict_rf = rf_clf.predict(x_test)\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf = GaussianNB()\n",
    "start = time.time()\n",
    "gnb_scores = cross_val_score(gnb_clf, x_train, y_train, cv = 10)\n",
    "print('Gaussian Naive Bayes CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(gnb_scores.mean(), gnb_scores.std()))\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gnb_clf.fit(x_train, y_train)\n",
    "y_predict_gnb = gnb_clf.predict(x_test)\n",
    "print ('Time elapsed: {0:1.2f}\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Separar dados para submissão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_knn = pd.DataFrame({'Income':y_predict_knn})\n",
    "df_pred_log = pd.DataFrame({'Income':y_predict_log})\n",
    "df_pred_rf = pd.DataFrame({'Income':y_predict_rf})\n",
    "df_pred_gnb = pd.DataFrame({'Income':y_predict_gnb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_knn.to_csv(\"knn_prediction.csv\", index = True, index_label = 'Id')\n",
    "df_pred_log.to_csv(\"log_prediction.csv\", index = True, index_label = 'Id')\n",
    "df_pred_rf.to_csv(\"rf_prediction.csv\", index = True, index_label = 'Id')\n",
    "df_pred_gnb.to_csv(\"gnb_prediction.csv\", index = True, index_label = 'Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os classificadores utilizados neste <i>notebook</i> foram, como se pode verificar acima, <b>K-Nearest Neighbors</b>, <b>Logistic Regression</b>, <b>Random Forest</b> e <b>(Gaussian) Naive Bayes</b>. O primeiro foi incluído apenas para facilitar a comparação dos resultados obtidos no trabalho anterior. No entanto, nos limitamos à aplicação das técnicas <i>label encoding</i> e <i>scaling</i> dos atributos, sem no entanto realizar <i>grid search</i> devido ao longo tempo de processamento. Quando necessário, foram selecionado hiperparâmetros que garantem resultados considerados satisfatórios.\n",
    "\n",
    "A ideia por trás deste trabalho foi comparar um pequeno conjunto de classificadores relativamente simples, comparáveis ao KNN, e ao mesmo tempo importantes; ou que partem de pressupostos que poderiam colocar sua eficácia em xeque num primeiro momento, como o <i>Naive Bayes</i> ou o <i>Random Forest</i>. Durante as aulas, foi enfatizado que, apesar da simplicidade, seus desempenhos são surpreendentes. Procurou-se verificar essa informação de maneira prática.\n",
    "\n",
    "Não houve diferença significativa percebida na dificuldade de gerar os algoritmos de classificação, mas o mais simples foi o <i>Naive Bayes</i>, que não exigiu configuração de hiperparâmetros e apresentou um resultado razoável, mas que também apresentou a menor acurácia nos testes por <i>cross validation</i>, apesar da rápida execução.\n",
    "\n",
    "Esses dois aspectos, relativa simplicidade e baixo tempo de execução combinados com altas acurácias, parecem explicar, ao menos em parte, por que esses algoritmos são considerados bem-sucedidos.\n",
    "\n",
    "Quanto ao tempo de execução da validação cruzada, os mais demorados foram, respectivamente, o <i>Random Forest</i> (devido em grande parte aos hiperparâmetros selecionados) e o <i>K-Nearest Neighbors</i>, que também alcançaram os melhores resultados para este experimento. Os tempos para treino e realização da predição são consideravelmente encurtados, especialmente no caso do <i>Random Forest</i>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
